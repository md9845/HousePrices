{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Kaggle competition for House Prices in Ames, Iowa.\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques'''\n",
    "   \n",
    "__author__ = 'Mike DiPalma'\n",
    "__email__ = 'mdipalma78@gmail.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor, StackingRegressor\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, train_file, test_file, cat_cols, num_cols, target_col, id_col, trans_cols, group_cols, \\\n",
    "                 engineer_features, one_hot_encode):\n",
    "        '''create train and test dataframe'''\n",
    "        #create new copies instead of references\n",
    "        self.cat_cols = list(cat_cols)\n",
    "        self.num_cols = list(num_cols)\n",
    "        self.group_cols = list(group_cols)\n",
    "        self.feature_cols = cat_cols + num_cols\n",
    "        self.target_col = target_col\n",
    "        self.id_col = id_col\n",
    "        self.label_encoders = {}\n",
    "        self.train_df, self.test_df, self.test_Id, self.comb_df, self.feature_cols = self._create_df(train_file, test_file, cat_cols, \\\n",
    "                                                                                  num_cols, target_col, id_col, \\\n",
    "                                                                                  trans_cols, group_cols, \\\n",
    "                                                                                  engineer_features, one_hot_encode)\n",
    "\n",
    "    def _create_df(self, train_file, test_file, cat_cols, num_cols, target_col, id_col, trans_cols, group_cols, \\\n",
    "                   engineer_features=False, one_hot_encode=False):\n",
    "        '''loads training and test data, combines, preprocesses, encodes and seperates data into df for modeling'''\n",
    "        train_df = self._load_data(train_file)\n",
    "        test_df = self._load_data(test_file)\n",
    "        # Save the test ID columnn for the submission file\n",
    "        test_Id = test_df['Id']\n",
    "        train_df = self._clean_data(train_df)\n",
    "        train_df = self._shuffle_data(train_df)\n",
    "        comb_df = self._combine_data(train_df, test_df)\n",
    "        comb_df = self._transform_data_types(comb_df, trans_cols)\n",
    "        comb_df = self._fill_NaN(comb_df, num_cols, cat_cols)\n",
    "        print(\"Engineer Features: \", engineer_features)\n",
    "        if engineer_features:\n",
    "            comb_df = self.aggregate_features(comb_df)\n",
    "            comb_df = self.add_group_stats(comb_df)\n",
    "        print(\"One-hot Encode: \", one_hot_encode)\n",
    "        if one_hot_encode:\n",
    "            comb_df = self._one_hot_encode_df(comb_df, self.cat_cols, self.num_cols, target_col)\n",
    "        train_df = comb_df[comb_df['log1pSalePrice'].notnull()]\n",
    "        feature_cols = comb_df.drop(['log1pSalePrice'], axis=1).columns\n",
    "        test_df = comb_df[comb_df['log1pSalePrice'].isnull()]\n",
    "        test_df = test_df.drop(['log1pSalePrice'], axis=1)\n",
    "        return train_df, test_df, test_Id, comb_df, feature_cols\n",
    "\n",
    "    def _create_test_df(self, test_file, label_encode=True):\n",
    "        '''loads and label encodes test data'''\n",
    "        test_df = self._load_data(test_file)\n",
    "        if label_encode:\n",
    "            self.one_hot_encode_df(test_df, self.cat_cols)\n",
    "        return test_df\n",
    "        \n",
    "    def _load_data(self, file):\n",
    "        '''loads csv to pd dataframe'''\n",
    "        return pd.read_csv(file)\n",
    "    \n",
    "    def _combine_data(self, train, test):    \n",
    "        '''Joins train and test dataframes and resets the index'''\n",
    "        comb_df = pd.concat([train, test], sort=False)\n",
    "        comb_df = comb_df.reset_index(drop=True) # reset index\n",
    "        return comb_df\n",
    "\n",
    "    def _transform_data_types(self, df, cols):\n",
    "        '''Converts number fields which should be strings'''\n",
    "        for col in cols:\n",
    "            df[col] = df[col].apply(str)\n",
    "        return df\n",
    "    \n",
    "    def _fill_NaN(self, df, num_cols, cat_cols):\n",
    "        ''' replaces Nan values based on data type'''\n",
    "        for col in (num_cols):\n",
    "            df[col].fillna(0.0, inplace=True)\n",
    "        for col in (cat_cols):\n",
    "            df[col].fillna('None', inplace=True)\n",
    "        return df\n",
    "\n",
    "    def _one_hot_encode_df(self, df, cat_cols=None, num_cols=None, tar_col=None):\n",
    "        '''performs one-hot encoding on all categorical variables and combines result with continous variables'''\n",
    "        cat_df = pd.get_dummies(df[cat_cols], drop_first=True)\n",
    "        num_df = df[num_cols].apply(pd.to_numeric)\n",
    "        tar_df = df[tar_col].apply(pd.to_numeric)\n",
    "        return pd.concat([cat_df, num_df, tar_df], axis=1)#,ignore_index=False)\n",
    "   \n",
    "    def _clean_data(self, df):\n",
    "        '''removes outliers and applies log1p transformation to SalePrice'''\n",
    "        df = df.drop(df[(df['GrLivArea']>4000) & (df['SalePrice']<300000)].index)\n",
    "        df['log1pSalePrice'] = np.log1p(df['SalePrice'])\n",
    "        df = df.drop(columns=['SalePrice'])\n",
    "        return df\n",
    "\n",
    "    def _shuffle_data(self, df):\n",
    "        return shuffle(df).reset_index(drop=True)        \n",
    "    \n",
    "    def aggregate_features(self, df):\n",
    "        '''Combines the values of numeric features'''\n",
    "        df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "        df['TotalBath'] = df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath'])\n",
    "        # update column lists\n",
    "        agg_cols = ['TotalSF', 'TotalBath']\n",
    "        self._extend_col_lists(num_cols=agg_cols)\n",
    "        return df\n",
    "\n",
    "    def _get_group_stats(self, df):\n",
    "        '''calculates group statistics'''\n",
    "        target_col = self.target_col\n",
    "        group_stats_df = pd.DataFrame({'group_mean': df.groupby(group_cols)[target_col].mean()})\n",
    "        group_stats_df['group_max'] = df.groupby(group_cols)[target_col].max()\n",
    "        group_stats_df['group_min'] = df.groupby(group_cols)[target_col].min()\n",
    "        group_stats_df['group_std'] = df.groupby(group_cols)[target_col].std()\n",
    "        group_stats_df['group_median'] = df.groupby(group_cols)[target_col].median()\n",
    "        group_stats_df.fillna(0, inplace=True)\n",
    "        return group_stats_df\n",
    "        \n",
    "    def add_group_stats(self, df):\n",
    "        '''adds group statistics to data stored in data object'''\n",
    "        #get group stats\n",
    "        group_stats_df = self._get_group_stats(df)\n",
    "        group_stats_df.reset_index(inplace=True)\n",
    "  \n",
    "        #merge derived columns to original df\n",
    "        df = self._merge_new_cols(df, group_stats_df, self.group_cols, fillna=False)\n",
    "        \n",
    "        #update column lists\n",
    "        group_stats_cols = ['group_mean', 'group_max', 'group_min', 'group_std', 'group_median']\n",
    "        self._extend_col_lists(num_cols=group_stats_cols)  \n",
    "        return df\n",
    "    \n",
    "    def _merge_new_cols(self, df, new_cols_df, keys, fillna=False):\n",
    "        '''merges engineered features with original df'''\n",
    "        df = pd.merge(df, new_cols_df, on=keys, how='left')\n",
    "        if fillna:\n",
    "            df.fillna(0, inplace=True)\n",
    "        return df\n",
    "        \n",
    "    def _extend_col_lists(self, cat_cols=[], num_cols=[]):\n",
    "        '''addes engineered feature cols to data col lists'''\n",
    "        self.num_cols.extend(num_cols)\n",
    "        self.cat_cols.extend(cat_cols)\n",
    "        self.feature_cols.extend(num_cols + cat_cols)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelContainer:\n",
    "    def __init__(self, models=[]):#, default_num_iters=10, verbose_lvl=0):\n",
    "        '''initializes model list and dicts'''\n",
    "        self.models = models\n",
    "        self.best_model = None\n",
    "        self.predictions = None\n",
    "        self.mean_rmse = {}\n",
    "        self.cv_std = {}\n",
    "        #self.default_num_iters = default_num_iters\n",
    "        #self.verbose_lvl = verbose_lvl\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        print(model)\n",
    "\n",
    "    def cross_validate(self, data, k=3, num_procs=1):\n",
    "        '''cross validate models using given data'''\n",
    "        # set table to table to populate with performance results\n",
    "        rmse_results = []\n",
    "        names = []\n",
    "        col = ['Algorithm', 'RMSE Mean', 'RMSE SD']\n",
    "        results_df = pd.DataFrame(columns=col)\n",
    "        i = 0\n",
    "\n",
    "        feature_df = data.train_df[data.feature_cols]\n",
    "        target_df = data.train_df[data.target_col]\n",
    "        for name, model in self.models:\n",
    "            print(name, model)\n",
    "            print(\"Evaluating {}...\".format(name))\n",
    "            neg_mse = cross_val_score(model, feature_df, target_df, cv=k, n_jobs=num_procs, scoring='neg_mean_squared_error')\n",
    "            cv_rmse_results = np.sqrt(-neg_mse)\n",
    "            self.mean_rmse[model] = np.mean(cv_rmse_results)\n",
    "            self.cv_std[model] = np.std(cv_rmse_results)\n",
    "            rmse_results.append(cv_rmse_results)\n",
    "            names.append(name)\n",
    "            results_df.loc[i] = [name,\n",
    "                                 round(cv_rmse_results.mean(), 4),\n",
    "                                 round(cv_rmse_results.std(), 4)]\n",
    "            i += 1\n",
    "        results_df = results_df.sort_values(by=['RMSE Mean'], ascending=True).reset_index(drop=True)\n",
    "        print(results_df)\n",
    "    \n",
    "    def select_best_model(self):\n",
    "        '''select model with lowest mse'''\n",
    "        self.best_model = min(self.mean_rmse, key=self.mean_rmse.get)\n",
    "        \n",
    "    def best_model_fit(self, features, targets):\n",
    "        '''fits best model'''\n",
    "        self.best_model.fit(features, targets)\n",
    "    \n",
    "    def best_model_predict(self, features):\n",
    "        '''scores features using best model'''\n",
    "        self.predictions = self.best_model.predict(features)\n",
    "        self.predictions = np.expm1(self.predictions)\n",
    "\n",
    "        \n",
    "    def save_results(self, model, mean_mse, predictions):\n",
    "        '''saves model, model summary, feature importances, and predictions'''\n",
    "        with open('model.txt', 'w') as file:\n",
    "            file.write(str(model))\n",
    "        np.savetxt('predictions.csv', predictions, delimiter=',')\n",
    "        #create_submission(test_df, test_ID, predictions)\n",
    "   \n",
    "    @staticmethod\n",
    "    def get_feature_importance(model, cols):\n",
    "        '''retrieves and sorts feature importances'''\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            feature_importances = pd.DataFrame({'feature':cols, 'importance':importances})\n",
    "            feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "            #set index to 'feature'\n",
    "            feature_importances.set_index('feature', inplace=True, drop=True)\n",
    "            return feature_importances[0:25]\n",
    "        else:\n",
    "            #some models don't have feature_importances_\n",
    "            return \"Feature importances do not exist for given model\"\n",
    "\n",
    "    def print_summary(self):\n",
    "        '''prints summary of models, best model, and feature importance'''\n",
    "        print('\\nModel Summaries:\\n')\n",
    "        for model in models.mean_rmse:\n",
    "            print('\\n', model, '\\n', 'RMSE:', models.mean_rmse[model])\n",
    "            print('\\n', 'Standard deviation during CV:\\n', models.cv_std[model])\n",
    "        print('\\nBest Model:\\n', models.best_model)\n",
    "        print('\\nMSE of Best Model\\n', models.mean_rmse[models.best_model])\n",
    "        print('\\nFeature Importances\\n', models.get_feature_importance(models.best_model, data.feature_cols))\n",
    "        #save results\n",
    "        print('Saving results.')\n",
    "        self.save_results(model, models.mean_rmse[model], self.predictions)\n",
    "        print('Creating submission file.')\n",
    "        self.create_submission(data.test_df, data.test_Id, self.predictions)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importances = self.get_feature_importance(models.best_model, data.feature_cols)\n",
    "            feature_importances[0:25].plot.bar(figsize=(20,10))\n",
    "            plt.show()\n",
    "        else:\n",
    "            #some models don't have feature_importances_\n",
    "            return \"Feature importances do not exist for given model\"\n",
    "        \n",
    "    def create_submission(self, test_df, test_ID, predictions):\n",
    "        sub_df = pd.DataFrame({'Id': test_ID.values.tolist(), 'SalePrice': pd.Series(models.predictions, index=test_df.index)})\n",
    "\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\") \n",
    "\n",
    "        sub_df.to_csv('submission-' + timestr + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters needed to create and run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of CV folds\n",
    "k = 5\n",
    "\n",
    "# define number of processors to use for parallel runs\n",
    "num_procs = 4\n",
    "\n",
    "# set verbose level for models\n",
    "verbose_lvl = 0\n",
    "\n",
    "# Define inputs\n",
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "\n",
    "# Define variables\n",
    "cat_cols = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', \\\n",
    "            'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', \\\n",
    "            'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \\\n",
    "            'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \\\n",
    "            'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', \\\n",
    "            'Functional', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', \\\n",
    "            'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition'] \n",
    "num_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \\\n",
    "            '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', \\\n",
    "            'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', \\\n",
    "            'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n",
    "target_col = 'log1pSalePrice'\n",
    "id_col = 'Id'\n",
    "transform_cols = ['MSSubClass', 'MoSold', 'YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', \\\n",
    "                  'OverallQual', 'OverallCond']\n",
    "group_cols = ['OverallQual']\n",
    "#group_cols = ['OverallQual', 'Neighborhood', 'YearBuilt', 'ExterQual', 'BsmtQual', 'GarageYrBlt', 'KitchenQual', \\\n",
    "#              'GarageFinish', 'YearRemodAdd', 'GarageType']\n",
    "# Turn feature engineering on/off\n",
    "engineer_features = True\n",
    "\n",
    "# Turn one-hot encoding on/off\n",
    "one_hot_encode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineer Features:  True\n",
      "One-hot Encode:  True\n"
     ]
    }
   ],
   "source": [
    "data = Data(train_file, test_file, cat_cols, num_cols, target_col, id_col, transform_cols, group_cols, engineer_features, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model container and add models to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear Regression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False))\n",
      "('Ridge Regression', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001))\n",
      "('Random Forest', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False))\n",
      "('Gradient Boosting Regressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=80,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False))\n",
      "('Stacking Regressor', StackingRegressor(meta_regressor=Ridge(alpha=1.0, copy_X=True,\n",
      "                                       fit_intercept=True, max_iter=None,\n",
      "                                       normalize=False, random_state=None,\n",
      "                                       solver='auto', tol=0.001),\n",
      "                  refit=True,\n",
      "                  regressors=(LinearRegression(copy_X=True, fit_intercept=True,\n",
      "                                               n_jobs=None, normalize=False),\n",
      "                              Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                                    max_iter=None, normalize=False,\n",
      "                                    random_state=None, so...\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        n_estimators=80,\n",
      "                                                        n_iter_no_change=None,\n",
      "                                                        presort='auto',\n",
      "                                                        random_state=None,\n",
      "                                                        subsample=1.0,\n",
      "                                                        tol=0.0001,\n",
      "                                                        validation_fraction=0.1,\n",
      "                                                        verbose=0,\n",
      "                                                        warm_start=False)),\n",
      "                  store_train_meta_features=False,\n",
      "                  use_features_in_secondary=False, verbose=0))\n",
      "('Support Vector Regressor', SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=0.008, gamma=0.0003,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))\n",
      "('Light GBM', LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, bagging_seed=8,\n",
      "              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              feature_fraction=0.2, feature_fraction_seed=8,\n",
      "              importance_type='split', learning_rate=0.01, max_bin=200,\n",
      "              max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=7000,\n",
      "              n_jobs=-1, num_leaves=6, objective='regression', random_state=42,\n",
      "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "              subsample_for_bin=200000, subsample_freq=0, verbose=-1))\n"
     ]
    }
   ],
   "source": [
    "#create model container\n",
    "models = ModelContainer()\n",
    "\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "rf = RandomForestRegressor(n_estimators=60, n_jobs=num_procs, max_depth=15, min_samples_split=80, \\\n",
    "                           max_features=8, verbose=verbose_lvl)\n",
    "gbr = GradientBoostingRegressor(n_estimators=80, max_depth=7, loss='ls', verbose=verbose_lvl)\n",
    "sr = StackingRegressor(regressors=(lr, ridge, rf, gbr), \\\n",
    "                       meta_regressor=ridge, \\\n",
    "                       use_features_in_secondary=False)\n",
    "svr = SVR(C= 20, epsilon= 0.008, gamma=0.0003)\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                         num_leaves=6,\n",
    "                         learning_rate=0.01, \n",
    "                         n_estimators=7000,\n",
    "                         max_bin=200, \n",
    "                         bagging_fraction=0.8,\n",
    "                         bagging_freq=4, \n",
    "                         bagging_seed=8,\n",
    "                         feature_fraction=0.2,\n",
    "                         feature_fraction_seed=8,\n",
    "                         min_sum_hessian_in_leaf = 11,\n",
    "                         verbose=-1,\n",
    "                         random_state=42)\n",
    "\n",
    "\n",
    "#add models to model container\n",
    "models.add_model(('Linear Regression', lr))\n",
    "models.add_model(('Ridge Regression', ridge))\n",
    "models.add_model(('Random Forest', rf))\n",
    "models.add_model(('Gradient Boosting Regressor', gbr))\n",
    "models.add_model(('Stacking Regressor', sr))\n",
    "models.add_model(('Support Vector Regressor', svr))\n",
    "models.add_model(('Light GBM', lightgbm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ensemble stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(lr, ridge, rf, gbr), \\\n",
    "                                meta_regressor=ridge, \\\n",
    "                                use_features_in_secondary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingCVRegressor(cv=5,\n",
       "                    meta_regressor=Ridge(alpha=1.0, copy_X=True,\n",
       "                                         fit_intercept=True, max_iter=None,\n",
       "                                         normalize=False, random_state=None,\n",
       "                                         solver='auto', tol=0.001),\n",
       "                    n_jobs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "                    refit=True,\n",
       "                    regressors=(LinearRegression(copy_X=True,\n",
       "                                                 fit_intercept=True,\n",
       "                                                 n_jobs=None, normalize=False),\n",
       "                                Ridge(alpha=1.0, copy_X=True,\n",
       "                                      fit_inte...\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=80,\n",
       "                                                          n_iter_no_change=None,\n",
       "                                                          presort='auto',\n",
       "                                                          random_state=None,\n",
       "                                                          subsample=1.0,\n",
       "                                                          tol=0.0001,\n",
       "                                                          validation_fraction=0.1,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False)),\n",
       "                    shuffle=True, store_train_meta_features=False,\n",
       "                    use_features_in_secondary=False, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen_model = stack_gen.fit(np.array(data.train_df[data.feature_cols]), np.array(data.train_df[data.target_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingCVRegressor(cv=5,\n",
       "                    meta_regressor=Ridge(alpha=1.0, copy_X=True,\n",
       "                                         fit_intercept=True, max_iter=None,\n",
       "                                         normalize=False, random_state=None,\n",
       "                                         solver='auto', tol=0.001),\n",
       "                    n_jobs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "                    refit=True,\n",
       "                    regressors=(LinearRegression(copy_X=True,\n",
       "                                                 fit_intercept=True,\n",
       "                                                 n_jobs=None, normalize=False),\n",
       "                                Ridge(alpha=1.0, copy_X=True,\n",
       "                                      fit_inte...\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=80,\n",
       "                                                          n_iter_no_change=None,\n",
       "                                                          presort='auto',\n",
       "                                                          random_state=None,\n",
       "                                                          subsample=1.0,\n",
       "                                                          tol=0.0001,\n",
       "                                                          validation_fraction=0.1,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False)),\n",
       "                    shuffle=True, store_train_meta_features=False,\n",
       "                    use_features_in_secondary=False, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_gen_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate models, then select, fit, and score test data with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "Evaluating Linear Regression...\n",
      "Ridge Regression Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Evaluating Ridge Regression...\n",
      "Random Forest RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "Evaluating Random Forest...\n",
      "Gradient Boosting Regressor GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=80,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Evaluating Gradient Boosting Regressor...\n",
      "Stacking Regressor StackingRegressor(meta_regressor=Ridge(alpha=1.0, copy_X=True,\n",
      "                                       fit_intercept=True, max_iter=None,\n",
      "                                       normalize=False, random_state=None,\n",
      "                                       solver='auto', tol=0.001),\n",
      "                  refit=True,\n",
      "                  regressors=(LinearRegression(copy_X=True, fit_intercept=True,\n",
      "                                               n_jobs=None, normalize=False),\n",
      "                              Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                                    max_iter=None, normalize=False,\n",
      "                                    random_state=None, so...\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        n_estimators=80,\n",
      "                                                        n_iter_no_change=None,\n",
      "                                                        presort='auto',\n",
      "                                                        random_state=None,\n",
      "                                                        subsample=1.0,\n",
      "                                                        tol=0.0001,\n",
      "                                                        validation_fraction=0.1,\n",
      "                                                        verbose=0,\n",
      "                                                        warm_start=False)),\n",
      "                  store_train_meta_features=False,\n",
      "                  use_features_in_secondary=False, verbose=0)\n",
      "Evaluating Stacking Regressor...\n",
      "Support Vector Regressor SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=0.008, gamma=0.0003,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Evaluating Support Vector Regressor...\n",
      "Light GBM LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, bagging_seed=8,\n",
      "              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              feature_fraction=0.2, feature_fraction_seed=8,\n",
      "              importance_type='split', learning_rate=0.01, max_bin=200,\n",
      "              max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=7000,\n",
      "              n_jobs=-1, num_leaves=6, objective='regression', random_state=42,\n",
      "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "              subsample_for_bin=200000, subsample_freq=0, verbose=-1)\n",
      "Evaluating Light GBM...\n",
      "                     Algorithm  RMSE Mean   RMSE SD\n",
      "0                    Light GBM     0.1211    0.0111\n",
      "1             Ridge Regression     0.1297    0.0062\n",
      "2  Gradient Boosting Regressor     0.1391    0.0092\n",
      "3                Random Forest     0.1993    0.0066\n",
      "4     Support Vector Regressor     0.3971    0.0099\n",
      "5           Stacking Regressor    26.7077   33.2825\n",
      "6            Linear Regression   214.7564  269.0680\n"
     ]
    }
   ],
   "source": [
    "models.cross_validate(data, k, num_procs=num_procs)\n",
    "models.select_best_model()\n",
    "models.best_model_fit(data.train_df[data.feature_cols], data.train_df[data.target_col])\n",
    "models.best_model_predict(data.test_df[data.feature_cols])\n",
    "#models.save_results(models.best_model, models.predictions, models.feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summaries:\n",
      "\n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
      " RMSE: 214.75639404483871\n",
      "\n",
      " Standard deviation during CV:\n",
      " 269.06799130877795\n",
      "\n",
      " Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001) \n",
      " RMSE: 0.12967115361840767\n",
      "\n",
      " Standard deviation during CV:\n",
      " 0.006180206892134598\n",
      "\n",
      " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
      "                      max_features=8, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=80,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=4,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False) \n",
      " RMSE: 0.1993116178122114\n",
      "\n",
      " Standard deviation during CV:\n",
      " 0.0066366547721243094\n",
      "\n",
      " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=80,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) \n",
      " RMSE: 0.13914535509080314\n",
      "\n",
      " Standard deviation during CV:\n",
      " 0.009247411115462406\n",
      "\n",
      " StackingRegressor(meta_regressor=Ridge(alpha=1.0, copy_X=True,\n",
      "                                       fit_intercept=True, max_iter=None,\n",
      "                                       normalize=False, random_state=None,\n",
      "                                       solver='auto', tol=0.001),\n",
      "                  refit=True,\n",
      "                  regressors=(LinearRegression(copy_X=True, fit_intercept=True,\n",
      "                                               n_jobs=None, normalize=False),\n",
      "                              Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                                    max_iter=None, normalize=False,\n",
      "                                    random_state=None, so...\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        n_estimators=80,\n",
      "                                                        n_iter_no_change=None,\n",
      "                                                        presort='auto',\n",
      "                                                        random_state=None,\n",
      "                                                        subsample=1.0,\n",
      "                                                        tol=0.0001,\n",
      "                                                        validation_fraction=0.1,\n",
      "                                                        verbose=0,\n",
      "                                                        warm_start=False)),\n",
      "                  store_train_meta_features=False,\n",
      "                  use_features_in_secondary=False, verbose=0) \n",
      " RMSE: 26.707730946178025\n",
      "\n",
      " Standard deviation during CV:\n",
      " 33.28254061932041\n",
      "\n",
      " SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=0.008, gamma=0.0003,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      " RMSE: 0.39707287073058745\n",
      "\n",
      " Standard deviation during CV:\n",
      " 0.00987838871239877\n",
      "\n",
      " LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, bagging_seed=8,\n",
      "              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              feature_fraction=0.2, feature_fraction_seed=8,\n",
      "              importance_type='split', learning_rate=0.01, max_bin=200,\n",
      "              max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=7000,\n",
      "              n_jobs=-1, num_leaves=6, objective='regression', random_state=42,\n",
      "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "              subsample_for_bin=200000, subsample_freq=0, verbose=-1) \n",
      " RMSE: 0.12109144758210433\n",
      "\n",
      " Standard deviation during CV:\n",
      " 0.01108232286468369\n",
      "\n",
      "Best Model:\n",
      " LGBMRegressor(bagging_fraction=0.8, bagging_freq=4, bagging_seed=8,\n",
      "              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              feature_fraction=0.2, feature_fraction_seed=8,\n",
      "              importance_type='split', learning_rate=0.01, max_bin=200,\n",
      "              max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=7000,\n",
      "              n_jobs=-1, num_leaves=6, objective='regression', random_state=42,\n",
      "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "              subsample_for_bin=200000, subsample_freq=0, verbose=-1)\n",
      "\n",
      "MSE of Best Model\n",
      " 0.12109144758210433\n",
      "\n",
      "Feature Importances\n",
      "                       importance\n",
      "feature                         \n",
      "LotArea                     1739\n",
      "1stFlrSF                    1572\n",
      "TotalSF                     1403\n",
      "GrLivArea                   1375\n",
      "BsmtUnfSF                   1341\n",
      "TotalBsmtSF                 1278\n",
      "GarageArea                  1204\n",
      "LotFrontage                 1075\n",
      "BsmtFinSF1                  1032\n",
      "OpenPorchSF                  906\n",
      "EnclosedPorch                862\n",
      "WoodDeckSF                   766\n",
      "2ndFlrSF                     669\n",
      "MasVnrArea                   561\n",
      "TotalBath                    539\n",
      "group_mean                   510\n",
      "group_max                    419\n",
      "group_min                    384\n",
      "SaleCondition_Normal         373\n",
      "BedroomAbvGr                 353\n",
      "group_std                    350\n",
      "TotRmsAbvGrd                 336\n",
      "group_median                 284\n",
      "Functional_Typ               243\n",
      "ScreenPorch                  225\n",
      "Saving results.\n",
      "Creating submission file.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
